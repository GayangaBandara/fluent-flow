ackend/.env.example</path>
<content"># Fluent Flow Voice Chat Bot - Configuration Template
# Copy this file to .env and fill in the values for the services you want to use

# ============================================================================
# OPTIONAL: Google Cloud Speech-to-Text & Text-to-Speech
# ============================================================================
# Get credentials from: https://cloud.google.com/speech-to-text
# Create a service account and download JSON key
GOOGLE_APPLICATION_CREDENTIALS=/path/to/your/google-service-account-key.json

# ============================================================================
# OPTIONAL: OpenAI API (ChatGPT - Highest Quality Responses)
# ============================================================================
# Get API key from: https://platform.openai.com/api-keys
# This will provide the best quality AI responses
OPENAI_API_KEY=sk-your-openai-api-key-here

# ============================================================================
# OPTIONAL: Hugging Face API (Free Tier Available)
# ============================================================================
# Get API key from: https://huggingface.co/settings/tokens
# Note: Free tier may be slow or timeout. Paid tier is more reliable.
HUGGINGFACE_API_KEY=hf_your-huggingface-api-key-here

# ============================================================================
# OPTIONAL: Ollama Local LLM (Free, Runs Locally - No API Key Needed!)
# ============================================================================
# Install from: https://ollama.ai
# Then run: ollama run mistral
# This provides good quality responses without internet or API costs
# Just ensure Ollama is running on localhost:11434 before starting the app
OLLAMA_ENABLED=false

# ============================================================================
# AI Response Priority (Auto-detected)
# ============================================================================
# The app will try these AI backends in order:
# 1. OpenAI (if OPENAI_API_KEY is set)
# 2. Ollama local (if running on localhost:11434)
# 3. Hugging Face (if HUGGINGFACE_API_KEY is set)
# 4. LOCAL FALLBACK (Always works! Pattern-based responses)
# 
# If all external services fail, the app uses a reliable local pattern
# matching system that always provides helpful responses.

# ============================================================================
# Recommendations by Use Case
# ============================================================================

# 1. BEST EXPERIENCE - Use OpenAI + Local Ollama Fallback:
#    OPENAI_API_KEY=sk-your-key
#    (Keep Ollama running in background for automatic fallback)

# 2. FREE & LOCAL - Use Ollama (No API keys needed):
#    Install Ollama and run: ollama run mistral
#    (No configuration needed - app auto-detects it)

# 3. NO SETUP - Just use local fallback:
#    Leave all API keys empty - app works perfectly!
#    (Responses are pattern-based but always helpful)

# 4. FREE CLOUD - Use Hugging Face:
#    HUGGINGFACE_API_KEY=hf_your-key
#    (Note: Free tier may timeout. Paid tier recommended)

# ============================================================================
# Development / Testing Configuration
# ============================================================================
DEBUG=false
LOG_LEVEL=INFO